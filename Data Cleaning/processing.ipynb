{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# interactive plotting with holoviews/bokeh.\n",
    "# Holoviews uses datashader as backend\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import datashade\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Key functionality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMaster(master):\n",
    "    \"\"\"\n",
    "    Function to read the master data file (cleaned and collated data for all devices)\n",
    "   \n",
    "    args:\n",
    "    master: string name of the master file with file extension, .csv\n",
    "    \n",
    "    return:\n",
    "    df: pandas dataframe containing the loaded data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(master)\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPMOverlay(curr_dev):\n",
    "    \"\"\"\n",
    "    Function to plot an overlay of different PM measurement time series (1.0, 2.5, 10.0) for a particular device\n",
    "    \n",
    "    args:\n",
    "    curr_dev: `device` field of the device in question \n",
    "    \n",
    "    return:\n",
    "    scatter: overlay plot holoviews object. To display it, use: `hv.output(scatter)`\n",
    "    \"\"\"\n",
    "    x = pd.to_datetime(curr_dev['when_captured']).values\n",
    "    line1 = hv.Scatter((x,curr_dev['pms_pm10_0']), label='PM10.0').opts(width=800, xlabel = 'date', ylabel = 'PMx')\n",
    "    line2 = hv.Scatter((x,curr_dev['pms_pm02_5']), label='PM2.5').opts(width=800)\n",
    "    line3 = hv.Scatter((x,curr_dev['pms_pm01_0']), label='PM1.0').opts(width=800)\n",
    "    scatter = line1*line2*line3\n",
    "    scatter.opts(legend_position='top_right')\n",
    "    return scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRadiationOverlay(curr_dev):\n",
    "    \"\"\"\n",
    "    Function to plot an overlay of different radiation measurement time series for a particular device\n",
    "    \n",
    "    args:\n",
    "    curr_dev: `device` field of the device in question \n",
    "    \n",
    "    return:\n",
    "    scatter: overlay plot holoviews object. To display it, use: `hv.output(scatter)`\n",
    "    \"\"\"\n",
    "    x = pd.to_datetime(curr_dev['when_captured']).values\n",
    "    line1 = hv.Scatter((x,curr_dev['lnd_7318u']), label='lnd_7318u')\\\n",
    "    .opts(width=800, xlabel = 'date', ylabel = 'Counts per minute (CPM)')\n",
    "    line2 = hv.Scatter((x,curr_dev['lnd_7318c']), label='lnd_7318c').opts(width=800)\n",
    "    scatter = line1*line2\n",
    "    scatter.opts(legend_position='top_right')\n",
    "    return scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativeField(field, curr_dev):\n",
    "    \"\"\"\n",
    "    Function to filter anomlous records based on negative (therefore meaningless) values of the `field`\n",
    "    \n",
    "    args:\n",
    "    field: string name of the field of interest for anomaly detection \n",
    "    curr_dev: `device` field of the device in question \n",
    "    \n",
    "    return:\n",
    "    faults: pandas dataframe with containing anaomalous records: 4 fields are in the list\n",
    "            ['anomaly_type','device','normalized_severity_score','when_captured']\n",
    "    \"\"\"\n",
    "    faults = curr_dev[curr_dev[field] < 0][['when_captured', 'device']]\n",
    "    faults['anomaly_type'] = np.repeat(field + ' < 0', faults.shape[0])\n",
    "    faults['normalized_severity_score'] = 1\n",
    "    return faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollingMeanDev(field, curr_dev, window, min_period, numStd):\n",
    "    \"\"\"\n",
    "    Function to filter anomlous records based on `numStd` number of deviations away from rolling mean\n",
    "    \n",
    "    args:\n",
    "    field: string name of the field of interest for anomaly detection \n",
    "    curr_dev: `device` field of the device in question \n",
    "    window: moving window size for the rolling mean and stddev\n",
    "    min_period: Minimum number of observations in window required to have a value (otherwise result is NA)\n",
    "    numStd: tolerance in number of standard deviations away from mean for record to be anomalous\n",
    "    \n",
    "    return:\n",
    "    pandas dataframe with containing anaomalous records: 4 fields are in the list\n",
    "            ['anomaly_type','device','normalized_severity_score','when_captured']\n",
    "    overlay: holoviews plot object with running mean, +/- numStd lines, and data\n",
    "    \"\"\"\n",
    "    rollingMean = curr_dev[field].rolling(window, min_periods=min_period).mean()\n",
    "    rollingStdev = curr_dev[field].rolling(window, min_periods=min_period).std()\n",
    "    upper = rollingMean + (rollingStdev * numStd)\n",
    "    lower = rollingMean - (rollingStdev * numStd)\n",
    "    \n",
    "    # visualize\n",
    "    x = pd.to_datetime(curr_dev['when_captured']).values\n",
    "    line1 = hv.Scatter((x,curr_dev[field]), label='data').opts(width=700, ylabel = field)\n",
    "    line1Mean = hv.Curve((x, rollingMean), label='mean').opts(width=700, color='red', xlabel = 'date')\n",
    "    line1Upper = hv.Curve((x, upper), label='mean+ 3.stdev').opts(width=700, color='blue')\n",
    "    line1Lower = hv.Curve((x, lower), label='mean- 3.stdev').opts(width=700, color='blue')\n",
    "    \n",
    "    overlay = line1Upper * line1Mean * line1 * line1Lower\n",
    "    overlay # there exists a save command too\n",
    "\n",
    "    # return the list of anomalies : records where deviation is >= num_std away from mean\n",
    "    temp = curr_dev.copy()\n",
    "    temp['rollingMean'] = rollingMean\n",
    "    temp['rollingStdev'] = rollingStdev\n",
    "    temp['normalized_severity_score'] = (temp[field]-temp['rollingMean'])/(numStd*temp['rollingStdev'])\n",
    "    temp = temp[abs(temp['normalized_severity_score']) >= 1]\n",
    "    \n",
    "    # instead of string for anomaly type, we can also make a key:value dictionary \n",
    "    # and use that as meta-data for reporting\n",
    "    temp['anomaly_type'] = np.repeat(field + ' ' + str(numStd) + ' or more away from mean', temp.shape[0])\n",
    "    return temp[['anomaly_type', 'device', 'normalized_severity_score', 'when_captured']], overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example Run**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the master csv file with data for all Solarcast devices since inception\n",
    "There are about 36 different Solarcast deployments.\n",
    "\n",
    "Keep the master data file in the same folder as this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = 'Solarcast-01_Master_Cleaned_Sorted.csv'\n",
    "df = readMaster(master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by `device` field\n",
    "Note that this `device` field is the unique device identifier (36 such). A single device can have different `device_urn` or `device_sn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = df.groupby('device') # remember the key is \"device\" not \"device_sn or device_urn\"\n",
    "devices = np.unique(df.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dev  = gf.get_group(devices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting AQ datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPMOverlay(curr_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the radiation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRadiationOverlay(curr_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Automated (aka unsupervised) anomaly detection**\n",
    "Flag errors for each of the following situtions -- idea is to draw attention of Safecast personnel\n",
    "\n",
    "*To Do:* **Need to expand it to more than 1 device (involves a loop over all the devices created by `grouping`)**\n",
    "\n",
    "We also want to tag the resulting `faulty` time stamps indicating which (one or more *To Do:* more?) among the below anomalies kicked in:\n",
    "\n",
    "0. If PM or radiation counts (CPM) are negative -- those are anomalies for sure\n",
    "1. 3 \"rolling stddev\" deviation away from mean (outside the 95% confidence interval)\n",
    "2. *To Do:* ? Poor rolling correlation between two time series at certain instances ?\n",
    "3. *To Do:* ? Add functionality for anomalies when there are no readings for a device for more than 2 days ?\n",
    "4. *To Do:* more from discussion on 08/13/2020?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes for storing reportable anomalies\n",
    "Create `anomalyf_air` and `anomalyf_rad` dataframes to contain list of all anomalies found for a particular device (separate dfs for air and radiation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['anomaly_type','device','normalized_severity_score','when_captured']\n",
    "anomalyf_air = pd.DataFrame(columns=cols)\n",
    "anomalyf_rad = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies: Negative PM or CPM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['pms_pm10_0', 'pms_pm02_5', 'pms_pm01_0']:\n",
    "    anomalyf_air = anomalyf_air.append(negativeField(field, curr_dev), ignore_index=True, sort=True)\n",
    "    \n",
    "# for radiation\n",
    "for field in ['lnd_7318u', 'lnd_7318c']:\n",
    "    anomalyf_rad = anomalyf_rad.append(negativeField(field, curr_dev), ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies: 3 std away from mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 std-dev deviation away from rolling mean:\n",
    "\n",
    "Tag as anomaly anything that is, say, 3 standard deviations away from the moving average.\n",
    "Notice that it's hard to tell what is an anomaly without making an assumption of what is normal i.e. what is the data generating process.\n",
    "\n",
    "*To Do:* Examine the effect of the `window` and `min_period` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters -- can be a different set for radiation and AQ measurements\n",
    "window = 300\n",
    "min_period = 100\n",
    "numStd = 3\n",
    "\n",
    "#store all plot objects in a list\n",
    "plots= []\n",
    "\n",
    "for field in ['pms_pm10_0', 'pms_pm02_5', 'pms_pm01_0']:\n",
    "    anom, plot = rollingMeanDev(field, curr_dev, window, min_period, numStd)\n",
    "    anomalyf_air = anomalyf_air.append(anom, ignore_index=True, sort=True)\n",
    "    plots.append(plot)\n",
    "\n",
    "# for radiation\n",
    "for field in ['lnd_7318u', 'lnd_7318c']:\n",
    "    anom, plot = rollingMeanDev(field, curr_dev, window, min_period, numStd)\n",
    "    anomalyf_rad = anomalyf_rad.append(anom, ignore_index=True, sort=True)\n",
    "    plots.append(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lower bound in plots below for the AQ msmts is meaningless. Just there for consistencyin code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot in plots:\n",
    "    hv.output(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyf_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"percent anomalous data = \", anomalyf_air.shape[0]/curr_dev.shape[0]*100) \n",
    "# check for uniqueness of when_captured by using group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyf_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"percent anomalous data = \", anomalyf_rad.shape[0]/curr_dev.shape[0]*100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
