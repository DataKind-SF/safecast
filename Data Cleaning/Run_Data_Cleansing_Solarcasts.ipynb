{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run cleaning algo functions from `Data_Cleansing_Single_file`\n",
    "### Saksham Gakhar, DA - DKSF\n",
    "\n",
    "Keep changing the input csv file and look for duplicate and multivalued records, enlist devices that generally misbehave..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64655 entries, 0 to 64654\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   service_uploaded  64655 non-null  datetime64[ns, UTC]\n",
      " 1   when_captured     61839 non-null  datetime64[ns, UTC]\n",
      " 2   device_urn        64655 non-null  object             \n",
      " 3   device_sn         64655 non-null  object             \n",
      " 4   device            64655 non-null  int64              \n",
      " 5   loc_lat           64655 non-null  float64            \n",
      " 6   loc_lon           64655 non-null  float64            \n",
      " 7   env_temp          36580 non-null  float64            \n",
      " 8   env_humid         36580 non-null  float64            \n",
      " 9   pms_pm01_0        36899 non-null  float64            \n",
      " 10  pms_pm02_5        36898 non-null  float64            \n",
      " 11  pms_pm10_0        36897 non-null  float64            \n",
      " 12  lnd_7318c         55230 non-null  float64            \n",
      " 13  lnd_7318u         55231 non-null  float64            \n",
      " 14  bat_voltage       24201 non-null  float64            \n",
      " 15  year              61839 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](2), float64(11), int64(1), object(2)\n",
      "memory usage: 7.9+ MB\n",
      "bad device data counts: \n",
      "                device_urn         device_sn             when_captured  size\n",
      "5634    safecast:114699387  Solarcast #30023 2017-09-11 08:30:04+00:00     5\n",
      "5639    safecast:114699387  Solarcast #30023 2017-09-11 14:45:03+00:00     5\n",
      "5635    safecast:114699387  Solarcast #30023 2017-09-11 09:45:04+00:00     5\n",
      "5636    safecast:114699387  Solarcast #30023 2017-09-11 11:00:03+00:00     5\n",
      "5637    safecast:114699387  Solarcast #30023 2017-09-11 12:15:03+00:00     5\n",
      "5638    safecast:114699387  Solarcast #30023 2017-09-11 13:30:03+00:00     5\n",
      "5633    safecast:114699387  Solarcast #30023 2017-09-11 06:00:04+00:00     5\n",
      "5641    safecast:114699387  Solarcast #30023 2017-09-11 16:00:03+00:00     3\n",
      "31971  safecast:3714913954  Solarcast #30027 2017-09-29 09:22:50+00:00     2\n",
      "32368  safecast:3714913954  Solarcast #30027 2017-09-30 13:52:50+00:00     2\n",
      "32417  safecast:3714913954  Solarcast #30027 2017-09-30 17:22:50+00:00     2\n",
      "31495  safecast:3714913954  Solarcast #30027 2017-09-28 10:47:38+00:00     2\n",
      "32382  safecast:3714913954  Solarcast #30027 2017-09-30 14:52:50+00:00     2\n",
      "28608  safecast:3714913954  Solarcast #30027 2017-09-21 09:25:23+00:00     2\n",
      "28780  safecast:3714913954  Solarcast #30027 2017-09-21 16:05:38+00:00     2\n",
      "32187  safecast:3714913954  Solarcast #30027 2017-09-30 00:52:50+00:00     2\n",
      "all bad device list: \n",
      "['Solarcast #30023' 'Solarcast #30027']\n",
      "Null date records to remove:  2816\n",
      "df shape after remove records with NULL `when_captured` :  (61839, 16)\n",
      "Valid `when_captured`  entires:  61839\n",
      "df shape after remove records where `when_captured` is an invalid :  (61839, 16)\n",
      "Lag 7 days to remove:  0\n",
      "df shape after records where gap of `service_uploaded` and `when_captured` > 7 days :  (61839, 16)\n",
      "new df:  (61839, 16)\n",
      "Inaccurate RH records imputed:  9102\n",
      "new df:  (61839, 16)\n",
      "new df after dropping service_uploaded col:  (61839, 15)\n",
      "Number of duplicative entries removed :  8\n",
      "new df after removing duplicates:  (61831, 15)\n",
      "num_groups  is :  61801\n",
      "(61801, 3) (61801, 3)\n",
      "merged:  (61801, 4)\n",
      "num_groups :  61801\n",
      "0\n",
      "8\n",
      "remaining duplicates check :  0\n",
      "good records :  61793\n",
      "toDiscard1 shape:  (0, 2)\n",
      "toDiscard3 shape:  (8, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8 entries, 40839 to 40847\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   device_sn      8 non-null      object             \n",
      " 1   when_captured  8 non-null      datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), object(1)\n",
      "memory usage: 192.0+ bytes\n",
      "written records count :  8\n",
      "(61831, 15) (8, 3)\n",
      "these many rows to discard:  38\n",
      "38\n",
      "final df shape:  (61793, 16)\n",
      "bad device data counts: \n",
      "Empty DataFrame\n",
      "Columns: [device_urn, device_sn, when_captured, size]\n",
      "Index: []\n",
      "all bad device list: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "%run Data_Cleansing_Single_file.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run cleaning algo functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSolarCastData(dt):\n",
    "    \"\"\"\n",
    "        Function to clean all the data with the helper functions in `Data_Cleansing_Single_file`\n",
    "        arg: dt: The function returns the cleaned data frame for the YYYY-MM corresponding to \"dt\"\n",
    "        return : df: cleaned dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = readCSV(dt)\n",
    "    findBadData(df)\n",
    "\n",
    "    df = rmInvalidTimeStamps(df)\n",
    "    print(\"new df: \", df.shape)\n",
    "\n",
    "    df = imputeInaccurateRH(df)\n",
    "    print(\"new df: \", df.shape)\n",
    "\n",
    "    dropServiceUploaded(df)\n",
    "    print(\"new df after dropping service_uploaded col: \", df.shape)\n",
    "\n",
    "    rmDuplicates(df)\n",
    "    print(\"new df after removing duplicates: \", df.shape)\n",
    "\n",
    "    merged,num_groups = dataAggWithKey(df)\n",
    "    print(\"merged: \", merged.shape)\n",
    "    print(\"num_groups : \", num_groups)\n",
    "\n",
    "    sum1, toDiscard1 = identifyALLNanRecs(merged)\n",
    "    sum3, toDiscard3 = identifyMultivaluedTimeStamps(merged)\n",
    "    sum2 = identifyRemainingDupl(merged)\n",
    "    sum4 = goodTimeStamps(merged)\n",
    "    print(\"toDiscard1 shape: \",toDiscard1.shape)\n",
    "    print(\"toDiscard3 shape: \",toDiscard3.shape)\n",
    "\n",
    "    # sanityCheck(): ensure you have all records covered by 1 of the 4 conditions\n",
    "    assert(num_groups == sum1+sum2+sum3+sum4)\n",
    "\n",
    "    writeDF(dt, toDiscard3, 'MultivaluedTimeStamps')\n",
    "\n",
    "    df = filterRows(toDiscard1, toDiscard3, df)\n",
    "    print(\"final df shape: \", df.shape)\n",
    "\n",
    "    ### Now check to make sure no garbage data is left\n",
    "\n",
    "    badRecordsLeft = findBadData(df)\n",
    "    badRecordsLeft\n",
    "    assert(badRecordsLeft.empty)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
