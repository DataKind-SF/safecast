{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Locating Multivalued and Duplicate records (single csv file)\n",
    "### Saksham Gakhar, DA - DKSF\n",
    "\n",
    "Keep changing the input csv file and look for duplicate and multivalued records, enlist devices that generally misbehave..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "# without mpld3\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2020-07-06-DataKind/output-2020-04-01T00_00_00+00_00.csv')\n",
    "df.when_captured = pd.to_datetime(df.when_captured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change the format of the Time Stamp for all the measurements in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56799 entries, 0 to 56798\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   service_uploaded  56799 non-null  datetime64[ns, UTC]\n",
      " 1   when_captured     56799 non-null  datetime64[ns, UTC]\n",
      " 2   device_urn        56799 non-null  object             \n",
      " 3   device_sn         56799 non-null  object             \n",
      " 4   device            56799 non-null  int64              \n",
      " 5   loc_lat           56799 non-null  float64            \n",
      " 6   loc_lon           56799 non-null  float64            \n",
      " 7   env_temp          16830 non-null  float64            \n",
      " 8   env_humid         16830 non-null  float64            \n",
      " 9   pms_pm01_0        23026 non-null  float64            \n",
      " 10  pms_pm02_5        23030 non-null  float64            \n",
      " 11  pms_pm10_0        23026 non-null  float64            \n",
      " 12  lnd_7318c         33293 non-null  float64            \n",
      " 13  lnd_7318u         49467 non-null  object             \n",
      " 14  bat_voltage       18462 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](2), float64(9), int64(1), object(3)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.service_uploaded =  df.service_uploaded.apply(lambda x: datetime.datetime.strptime(x, '%b %d, %Y @ %H:%M:%S.%f')\\\n",
    "                                                 .replace(tzinfo=datetime.timezone.utc))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_uploaded</th>\n",
       "      <th>when_captured</th>\n",
       "      <th>device_urn</th>\n",
       "      <th>device_sn</th>\n",
       "      <th>device</th>\n",
       "      <th>loc_lat</th>\n",
       "      <th>loc_lon</th>\n",
       "      <th>env_temp</th>\n",
       "      <th>env_humid</th>\n",
       "      <th>pms_pm01_0</th>\n",
       "      <th>pms_pm02_5</th>\n",
       "      <th>pms_pm10_0</th>\n",
       "      <th>lnd_7318c</th>\n",
       "      <th>lnd_7318u</th>\n",
       "      <th>bat_voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-30 23:59:23+00:00</td>\n",
       "      <td>2020-04-30 23:59:23+00:00</td>\n",
       "      <td>safecast:3714913954</td>\n",
       "      <td>Solarcast #30027</td>\n",
       "      <td>3714913954</td>\n",
       "      <td>52.395</td>\n",
       "      <td>4.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-30 23:57:54+00:00</td>\n",
       "      <td>2020-04-30 23:57:54+00:00</td>\n",
       "      <td>safecast:678194983</td>\n",
       "      <td>Solarcast #30030</td>\n",
       "      <td>678194983</td>\n",
       "      <td>46.554</td>\n",
       "      <td>15.635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29</td>\n",
       "      <td>3.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-30 23:57:37+00:00</td>\n",
       "      <td>2020-04-30 23:57:39+00:00</td>\n",
       "      <td>safecast:678194983</td>\n",
       "      <td>Solarcast #30030</td>\n",
       "      <td>678194983</td>\n",
       "      <td>46.554</td>\n",
       "      <td>15.635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-30 23:57:20+00:00</td>\n",
       "      <td>2020-04-30 23:57:15+00:00</td>\n",
       "      <td>safecast:678194983</td>\n",
       "      <td>Solarcast #30030</td>\n",
       "      <td>678194983</td>\n",
       "      <td>46.554</td>\n",
       "      <td>15.635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-30 23:45:01+00:00</td>\n",
       "      <td>2020-04-30 23:45:01+00:00</td>\n",
       "      <td>safecast:3714913954</td>\n",
       "      <td>Solarcast #30027</td>\n",
       "      <td>3714913954</td>\n",
       "      <td>52.395</td>\n",
       "      <td>4.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           service_uploaded             when_captured           device_urn  \\\n",
       "0 2020-04-30 23:59:23+00:00 2020-04-30 23:59:23+00:00  safecast:3714913954   \n",
       "1 2020-04-30 23:57:54+00:00 2020-04-30 23:57:54+00:00   safecast:678194983   \n",
       "2 2020-04-30 23:57:37+00:00 2020-04-30 23:57:39+00:00   safecast:678194983   \n",
       "3 2020-04-30 23:57:20+00:00 2020-04-30 23:57:15+00:00   safecast:678194983   \n",
       "4 2020-04-30 23:45:01+00:00 2020-04-30 23:45:01+00:00  safecast:3714913954   \n",
       "\n",
       "          device_sn      device  loc_lat  loc_lon  env_temp  env_humid  \\\n",
       "0  Solarcast #30027  3714913954   52.395    4.875       NaN        NaN   \n",
       "1  Solarcast #30030   678194983   46.554   15.635       NaN        NaN   \n",
       "2  Solarcast #30030   678194983   46.554   15.635       NaN        NaN   \n",
       "3  Solarcast #30030   678194983   46.554   15.635       NaN        NaN   \n",
       "4  Solarcast #30027  3714913954   52.395    4.875       NaN        NaN   \n",
       "\n",
       "   pms_pm01_0  pms_pm02_5  pms_pm10_0  lnd_7318c lnd_7318u  bat_voltage  \n",
       "0         NaN         NaN         NaN       23.0        25          NaN  \n",
       "1         NaN         NaN         NaN       24.0        29        3.876  \n",
       "2         NaN         NaN         NaN        NaN       NaN          NaN  \n",
       "3         1.0         2.0         2.0        NaN       NaN          NaN  \n",
       "4         NaN         NaN         NaN        NaN       NaN          NaN  "
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above table for (`device`, `when_captured`) key, let's see what these multiple values for each time stamp correspond to. Sometimes there are negative RH, sometimes 0.0 PM (which measn very clean air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBadData(df):\n",
    "    \n",
    "    temp_df = df.groupby(['device_urn', 'device_sn','when_captured']).size().to_frame('size').\\\n",
    "                                    reset_index().sort_values('size', ascending=False)\n",
    "    print(\"bad device data counts: \")\n",
    "    print(temp_df[(temp_df['size']>1)])\n",
    "    \n",
    "    print(\"all bad device list: \")\n",
    "    # Devices that have misbehaved at some point - more than one data values per time stamp\n",
    "    print(np.unique(temp_df[temp_df['size']>1]['device_sn'].values)) # devices that have misbehaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad device data counts: \n",
      "                device_urn         device_sn             when_captured  size\n",
      "15012  safecast:2152053642  Solarcast #30025 2020-04-07 15:59:56+00:00    24\n",
      "1678   safecast:1094924990  Solarcast #30024 2020-04-15 22:36:25+00:00    19\n",
      "32529  safecast:3768313999  Solarcast #30026 2020-04-20 05:44:22+00:00    19\n",
      "15341  safecast:2152053642  Solarcast #30025 2020-04-20 03:24:01+00:00    17\n",
      "32057  safecast:3768313999  Solarcast #30026 2020-04-06 06:24:45+00:00    17\n",
      "...                    ...               ...                       ...   ...\n",
      "31863  safecast:3714913954  Solarcast #30027 2020-04-30 16:14:23+00:00     2\n",
      "31166  safecast:3714913954  Solarcast #30027 2020-04-27 08:44:24+00:00     2\n",
      "28394  safecast:3714913954  Solarcast #30027 2020-04-13 18:22:34+00:00     2\n",
      "28269  safecast:3714913954  Solarcast #30027 2020-04-13 03:52:46+00:00     2\n",
      "28524  safecast:3714913954  Solarcast #30027 2020-04-14 08:52:34+00:00     2\n",
      "\n",
      "[1080 rows x 4 columns]\n",
      "all bad device list: \n",
      "['Solarcast #30000' 'Solarcast #30001' 'Solarcast #30002'\n",
      " 'Solarcast #30003' 'Solarcast #30006' 'Solarcast #30007'\n",
      " 'Solarcast #30012' 'Solarcast #30013' 'Solarcast #30014'\n",
      " 'Solarcast #30016' 'Solarcast #30017' 'Solarcast #30018'\n",
      " 'Solarcast #30019' 'Solarcast #30022' 'Solarcast #30023'\n",
      " 'Solarcast #30024' 'Solarcast #30025' 'Solarcast #30026'\n",
      " 'Solarcast #30027' 'Solarcast #33001' 'Solarcast #33003'\n",
      " 'Solarcast #33008' 'Solarcast #33009']\n"
     ]
    }
   ],
   "source": [
    "findBadData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a column for the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.DatetimeIndex(df['when_captured']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing based on [Protocol](https://github.com/DataKind-SF/safecast/blob/master/Solarcast_data_cleansing.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56799, 16)"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['when_captured'].isna().sum())\n",
    "df = df[df['when_captured'].notna()]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56799, 16)"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_condition = df['when_captured'] >  pd.to_datetime(2000/1/19, infer_datetime_format=True).tz_localize('UTC')\n",
    "print(boolean_condition.sum())\n",
    "df = df[df['when_captured'] >  pd.to_datetime(2000/1/19, infer_datetime_format=True).tz_localize('UTC')]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56799, 16)"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_condition = (df['env_humid']<0) | (df['env_humid']>100)\n",
    "print(boolean_condition.sum())\n",
    "column_name = 'env_humid'\n",
    "new_value = np.nan\n",
    "df.loc[boolean_condition, column_name] = new_value\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54385, 16)"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_condition = abs(df['when_captured'].subtract(df['service_uploaded'])).astype('timedelta64[D]') < 7\n",
    "boolean_condition.shape\n",
    "print(df.shape[0] - (boolean_condition).sum())\n",
    "df = df[boolean_condition]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont need the following column ANY MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54385, 15)"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('service_uploaded', axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all duplicates are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    }
   ],
   "source": [
    "incoming = df.shape[0]\n",
    "df.drop_duplicates(subset=df.columns[0:df.shape[1]], inplace=True, keep='first') # args: subset=[df.columns[0:df.shape[1]]], keep = 'first'\n",
    "print(-df.shape[0]+incoming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering bad row records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50076\n"
     ]
    }
   ],
   "source": [
    "temp_df = df.groupby(['device_sn','when_captured']).agg(['count','nunique'])\n",
    "# temp_df.info()\n",
    "num_groups = temp_df.shape[0]\n",
    "print(num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Counts and Count-Distincts to check for duplicative records and multiplicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50076, 3) (50076, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_sn</th>\n",
       "      <th>when_captured</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>DISTINCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solarcast #30000</td>\n",
       "      <td>2020-04-17 14:55:22+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solarcast #30000</td>\n",
       "      <td>2020-04-17 15:29:47+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Solarcast #30000</td>\n",
       "      <td>2020-04-17 16:39:11+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solarcast #30000</td>\n",
       "      <td>2020-04-17 17:38:13+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solarcast #30000</td>\n",
       "      <td>2020-04-17 18:07:07+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50071</th>\n",
       "      <td>Solarcast #33009</td>\n",
       "      <td>2020-04-28 22:34:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50072</th>\n",
       "      <td>Solarcast #33009</td>\n",
       "      <td>2020-04-29 10:44:17+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50073</th>\n",
       "      <td>Solarcast #33009</td>\n",
       "      <td>2020-04-29 22:54:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50074</th>\n",
       "      <td>Solarcast #33009</td>\n",
       "      <td>2020-04-30 11:04:13+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50075</th>\n",
       "      <td>Solarcast #33009</td>\n",
       "      <td>2020-04-30 21:12:08+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50076 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              device_sn             when_captured  COUNTS  DISTINCTS\n",
       "0      Solarcast #30000 2020-04-17 14:55:22+00:00       6          6\n",
       "1      Solarcast #30000 2020-04-17 15:29:47+00:00       6          5\n",
       "2      Solarcast #30000 2020-04-17 16:39:11+00:00       6          5\n",
       "3      Solarcast #30000 2020-04-17 17:38:13+00:00       6          5\n",
       "4      Solarcast #30000 2020-04-17 18:07:07+00:00       6          6\n",
       "...                 ...                       ...     ...        ...\n",
       "50071  Solarcast #33009 2020-04-28 22:34:19+00:00       1          1\n",
       "50072  Solarcast #33009 2020-04-29 10:44:17+00:00       1          1\n",
       "50073  Solarcast #33009 2020-04-29 22:54:14+00:00       1          1\n",
       "50074  Solarcast #33009 2020-04-30 11:04:13+00:00       1          1\n",
       "50075  Solarcast #33009 2020-04-30 21:12:08+00:00       1          1\n",
       "\n",
       "[50076 rows x 4 columns]"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even = list(range(0,26,2))\n",
    "odd = list(range(1,26,2))\n",
    "tmp_df1 = temp_df.iloc[:,even].max(axis=1).to_frame('COUNTS').reset_index()\n",
    "tmp_df2 = temp_df.iloc[:,odd].max(axis=1).to_frame('DISTINCTS').reset_index()\n",
    "print(tmp_df1.shape, tmp_df2.shape)\n",
    "merged = pd.merge(tmp_df1, tmp_df2, left_on = ['device_sn', 'when_captured'], right_on=['device_sn', 'when_captured'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating hits: Impose mutually exclusive conditions for filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actionable: Records of useless data with all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool1 = (merged.COUNTS >1) & (merged.DISTINCTS==0)\n",
    "sum1 = bool1.sum()\n",
    "print(sum1)\n",
    "toDiscard1 = merged.loc[:,['device_sn', 'when_captured']][bool1]\n",
    "toDiscard1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actionable: Records that are a mix of duplicates and non-duplicate rows for a given (`device_sn`, `when_captured`) [must be all discarded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(923, 2)"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool3 = (merged.COUNTS >1) & (merged.DISTINCTS>1)\n",
    "sum3 = bool3.sum()\n",
    "print(sum3)\n",
    "toDiscard3 = merged.loc[:,['device_sn', 'when_captured']][bool3]\n",
    "toDiscard3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT Actionable as duplicates were dropped: Records where all rows are purely duplicates [preserve only 1 later]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "get rid of :  0\n"
     ]
    }
   ],
   "source": [
    "bool2 = (merged.COUNTS >1) & (merged.DISTINCTS==1)\n",
    "sum2 = bool2.sum()\n",
    "print(sum2)\n",
    "print(\"get rid of : \" ,merged.COUNTS[bool2].sum() - merged.DISTINCTS[bool2].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records that are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49153\n"
     ]
    }
   ],
   "source": [
    "bool4 = (merged.COUNTS ==1) & (merged.DISTINCTS==1)\n",
    "sum4 = bool4.sum()\n",
    "print(sum4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure you have all records covered by 1 of the 4 conditions\n",
    "assert(num_groups == sum1+sum2+sum3+sum4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter now from the main dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54119, 15) (923, 3)\n"
     ]
    }
   ],
   "source": [
    "discard = pd.concat([toDiscard1, toDiscard3], ignore_index=True)\n",
    "discard['KEY_DevSN_WhenCapt'] = list(zip(discard.device_sn, discard.when_captured))\n",
    "print(df.shape, discard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54119, 16)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KEY_DevSN_WhenCapt'] = list(zip(df.device_sn, df.when_captured))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these many rows to discard:  4966\n"
     ]
    }
   ],
   "source": [
    "rows_to_discard = df['KEY_DevSN_WhenCapt'].isin(discard['KEY_DevSN_WhenCapt'])\n",
    "print(\"these many rows to discard: \", rows_to_discard.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966\n"
     ]
    }
   ],
   "source": [
    "incoming = df.shape[0]\n",
    "df = df[~rows_to_discard]\n",
    "print(incoming - df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now check to make sure no garbage data is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad device data counts: \n",
      "Empty DataFrame\n",
      "Columns: [device_urn, device_sn, when_captured, size]\n",
      "Index: []\n",
      "all bad device list: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "findBadData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
